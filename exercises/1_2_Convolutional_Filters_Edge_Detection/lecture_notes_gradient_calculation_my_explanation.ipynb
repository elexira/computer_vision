{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the weight is a filter. in this case a high freq pass filter, because it preservers and detects the edges.\n",
    "edges are high frequency because they represent sharp change in pixel intensity. \n",
    "to understand how a sharp increase in intensity is related to freq you need to understand how FFT extract frequencies from an image. All i see is that after applying such filters the output is an image of edges. if we pass that to the FFT we get frequncies far from center which means images of edges of an original image contain high frequency content. \n",
    "remember edge is not corner, edge here is contour around objects that distinguishes one object from another. \n",
    "\n",
    "the weight filter below is convolved on the pink patch of the original image on the right. the result of convolution is shown in the matrix buttom left. you add up all the numbers and get 60. 60 is assigned to the center pixel in the original image marked with orange. if you apply the weight filter to all patches in the image and calculate the sums (like 60 in this example), the resulting image is a the same size as the original image, but with very different pixel values. \n",
    "\n",
    "![gradient calculations](./images/snap_lecture_notes.png)\n",
    "\n",
    "60 is not high value, is is a dark pixel, showing that the value of pixel in the patc are not changing much. a higher value close to white (255), indicates much stronger edge.see image below for white color lines\n",
    "\n",
    "![gradient calculations](./images/snap_lecture_notes_2.png)\n",
    "\n",
    "\n",
    "when passing the filter across the original image, the edges become tricky if you want the final image to the same size as the original image. Below are some common strategies to calculaye filtered image around edges.\n",
    "\n",
    "Edge Handling\n",
    "\n",
    "Kernel convolution relies on centering a pixel and looking at it's surrounding neighbors. So, what do you do if there are no surrounding pixels like on an image corner or edge? Well, there are a number of ways to process the edges, which are listed below. It’s most common to use padding, cropping, or extension. In extension, the border pixels of an image are copied and extended far enough to result in a filtered image of the same size as the original image.\n",
    "\n",
    "Extend The nearest border pixels are conceptually extended as far as necessary to provide values for the convolution. Corner pixels are extended in 90° wedges. Other edge pixels are extended in lines.\n",
    "\n",
    "Padding The image is padded with a border of 0's, black pixels.\n",
    "\n",
    "Crop Any pixel in the output image which would require values from beyond the edge is skipped. This method can result in the output image being slightly smaller, with the edges having been cropped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Gradient Magnitude and Direction with Sobel Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider we apply the same filter above, but twice. First we apply sobel_x , it is sensitive to veritcle edges \n",
    "and then sobel_y which extracts horizonal edges. \n",
    "the final images from each of these filters is the same as the original image.\n",
    "we will combine the two filter reults to calculate at each pixel of the original image, the magnitude and direction of gradient (represents how intensly color changes around the pixel in the direction of gradient)\n",
    "to get the final intensity of the gradient is calculated with formulas below. Notice the gradient direction is perpendicular to the directio of the edge. because along that direction the intensity of pixel changes the most.\n",
    "![gradient calculations](./images/snap_lecture_notes3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notice gradient directio is perpendicular to the directio of the edge detected\n",
    "![gradient vector as a feature](./.../snap_gradient.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision_class",
   "language": "python",
   "name": "comp_vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
