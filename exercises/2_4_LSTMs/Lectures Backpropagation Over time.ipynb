{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackPropagation Overtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![backprop overtime 1](./images/snap_lecture_back1.png)\n",
    "![backprop overtime 2](./images/snap_lecture_back2.png)\n",
    "### simplest gradient calculation is for Wy. You can see output of the RNN in step 3 and its relation with Wy. The output of step 3 is not related at all to the Wy from the previous ouput. But,  S3 value for example clearly depends on S(2) \n",
    "![backprop overtime 3](./images/snap_lecture_back3.png)\n",
    "### key observation here is that S3 value depends on all previous S(i)s, if you are in this situation you need to accumulate gradients of the contributing term as shown below. The vanishing Gradient is as the you go further and futher back in time the partial derevatives become smaller. \n",
    "![backprop overtime 4](./images/snap_lecture_back4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the elephant goes into the forget gate where we decide how much of the Long term memory we should forget \n",
    "the learn gate gets the current evet and short term memory, Fish, combined \n",
    "the output from above are used for both remember gate and use gate\n",
    "[watch video](https://www.youtube.com/watch?time_continue=133&v=gjb68a4XsqE&feature=emb_logo)\n",
    "\n",
    "![backprop overtime 5](./images/snap_lecture_back5.png)\n",
    "\n",
    "![backprop overtime 6](./images/snap_lecture_back6.png)\n",
    "\n",
    "![backprop overtime 7](./images/snap_lecture_back7.png)\n",
    "### Let's zoom into learn gate\n",
    "![Let's zoom into memory gate](./images/snap_lecture_back8.png)\n",
    "\n",
    "### Let's zoom into forget gate\n",
    "![Let's zoom into forget gate](./images/snap_lecture_back9.png)\n",
    "\n",
    "### Let's zoom into remember gate\n",
    "![Let's zoom into remember gate](./images/snap_lecture_back10.png)\n",
    "\n",
    "\n",
    "### Let's zoom into use gate. This gates output is (1) prediction for this time step (2) short term memory for next time step\n",
    "![Let's zoom into use gate](./images/snap_lecture_back11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "433*1600"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision_class",
   "language": "python",
   "name": "comp_vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
